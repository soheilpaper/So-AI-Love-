{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soheilpaper/So-AI-Love-/blob/master/notebooks/1.0-test-noise-reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:43.350443Z",
          "start_time": "2020-01-24T06:23:43.339644Z"
        },
        "id": "zNOKLsvCroFh"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#%env CUDA_VISIBLE_DEVICES=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBNC6SHmroFy"
      },
      "source": [
        "#### Download packages if in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:43.360160Z",
          "start_time": "2020-01-24T06:23:43.352241Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF9MIpGcroF6",
        "outputId": "1e439bcb-266e-467e-e707-1413621eb113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (5.1.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting noisereduce\n",
            "Downloading noisereduce-2.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (from noisereduce) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from noisereduce) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from noisereduce) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from noisereduce) (4.64.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from noisereduce) (3.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (3.0.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (0.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (21.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa->noisereduce) (5.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa->noisereduce) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->noisereduce) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa->noisereduce) (3.11.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->noisereduce) (1.15.0)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile) (2.21)\n"
          ]
        }
      ],
      "source": [
        "colab_requirements = [\n",
        "    \"pip install librosa\",\n",
        "    \"pip install noisereduce\",\n",
        "    \"pip install soundfile\",\n",
        "    \"pip install pseudo-microbit\",\n",
        "    \"pip install keyboard\"\n",
        "\n",
        "]\n",
        "\n",
        "import sys, subprocess\n",
        "\n",
        "def run_subprocess_command(cmd):\n",
        "    # run the command\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "    # print the output\n",
        "    for line in process.stdout:\n",
        "        print(line.decode().strip())\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if IN_COLAB:\n",
        "    for i in colab_requirements:\n",
        "        run_subprocess_command(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkz66p9VroGA"
      },
      "source": [
        "# Test noise reduction algorithm and view steps of algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.000667Z",
          "start_time": "2020-01-24T06:23:43.361344Z"
        },
        "id": "TU0trOXRroGD"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "from scipy.io import wavfile\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from noisereduce.generate_noise import band_limited_noise\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import io\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPCbLKBroGG"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "!pip install -q omegaconf torchaudio pydub\n",
        "\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "if not exists('silero-models'):\n",
        "  !git clone -q --depth 1 https://github.com/snakers4/silero-models\n",
        "\n",
        "%cd silero-models\n",
        "\n",
        "# silero imports\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from omegaconf import OmegaConf\n",
        "from src.silero.utils import (init_jit_model, \n",
        "                       split_into_batches,\n",
        "                       read_audio,\n",
        "                       read_batch,\n",
        "                       prepare_model_input)\n",
        "from colab_utils import (record_audio,\n",
        "                         audio_bytes_to_np,\n",
        "                         upload_audio)\n",
        "\n",
        "device = torch.device('cpu')   # you can use any pytorch device\n",
        "models = OmegaConf.load('models.yml')\n",
        "\n",
        "# imports for uploading/recording\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio, display, clear_output\n",
        "from torchaudio.functional import vad\n",
        "\n",
        "\n",
        "# wav to text method\n",
        "def wav_to_text(f='test.wav'):\n",
        "  batch = read_batch([f])\n",
        "  input = prepare_model_input(batch, device=device)\n",
        "  output = model(input)\n",
        "  return decoder(output[0].cpu())"
      ],
      "metadata": {
        "id": "L_7cF0dMzp8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown { run: \"auto\" }\n",
        "\n",
        "language = \"English\" #@param [\"English\", \"German\", \"Spanish\"]\n",
        "\n",
        "print(language)\n",
        "if language == 'German':\n",
        "  model, decoder = init_jit_model(models.stt_models.de.latest.jit, device=device)\n",
        "elif language == \"Spanish\":\n",
        "  model, decoder = init_jit_model(models.stt_models.es.latest.jit, device=device)\n",
        "else:\n",
        "  model, decoder = init_jit_model(models.stt_models.en.latest.jit, device=device)"
      ],
      "metadata": {
        "id": "uIvd-KyezqMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown { run: \"auto\" }\n",
        "\n",
        "use_VAD = \"No\" #@param [\"Yes\", \"No\"]"
      ],
      "metadata": {
        "id": "IULCt34W0OHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
        "\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =  8 #@param {type:\"number\", min:1, max:10, step:1}\n",
        "sample_rate = 16000\n",
        "global rec_v\n",
        "rec_v=0\n",
        "\n",
        "def _apply_vad(audio, boot_time=0, trigger_level=9, **kwargs):\n",
        "  print('\\nVAD applied\\n')\n",
        "  vad_kwargs = dict(locals().copy(), **kwargs)\n",
        "  vad_kwargs['sample_rate'] = sample_rate\n",
        "  del vad_kwargs['kwargs'], vad_kwargs['audio']\n",
        "  audio = vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "  return vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "\n",
        "def _recognize(audio):\n",
        "  display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "  if use_VAD == \"Yes\":\n",
        "    audio = _apply_vad(audio)\n",
        "  wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  transcription = wav_to_text()\n",
        "  print('\\n\\nTRANSCRIPTION:\\n')\n",
        "  print(transcription)\n",
        "\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds)\n",
        "  wavfile.write('recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  _recognize(audio)\n",
        "  \n",
        "  rec_v=1\n",
        "  #while True:\n",
        "     \n",
        "  return rec_v\n",
        "\n",
        "  \n",
        "\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio()\n",
        "  _recognize(audio)\n",
        "  return audio\n",
        "import keyboard\n",
        "\n",
        "if True:\n",
        "   if record_or_upload == \"Record\":\n",
        "      button = widgets.Button(description=\"Record Speech\")\n",
        "      display(button)\n",
        "      if True :\n",
        "          button.on_click(_record_audio)\n",
        "          #if rec_v == \"1\":\n",
        "\n",
        "             #break\n",
        "      #input('press key to continue')\n",
        "      \n",
        "      #keyboard.get_event()\n",
        "      \n",
        "      #while rec_v!=1:\n",
        "      #    print (\"wating\")\n",
        "\n",
        "   else:\n",
        "      audio = _upload_audio(\"\")\n",
        "      rec_v=1"
      ],
      "metadata": {
        "id": "OZMdKf-v0LY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Check audio after applying VAD { run: \"auto\" }\n",
        "\n",
        "if record_or_upload == \"Record\":\n",
        "  audio = read_audio('recorded.wav', sample_rate)\n",
        "display(Audio(_apply_vad(audio), rate=sample_rate, autoplay=True))"
      ],
      "metadata": {
        "id": "kn1-HG-d0T6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check file"
      ],
      "metadata": {
        "id": "-4WyeC0w0Uym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get install ffmpeg\n",
        "#!sudo apt-get install -y python-pydub\n",
        "#!pip install pydub\n",
        "# import required modules \n",
        "from os import path \n",
        "from pydub import AudioSegment \n",
        "# we need pydub for later\n",
        "#! pip3  install pydub"
      ],
      "metadata": {
        "id": "pBIOO--Mteoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from scipy.io import wavfile\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from noisereduce.generate_noise import band_limited_noise\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import io\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "N29_E4D2thYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# and this\n",
        "from google.colab import files\n",
        "!pwd\n",
        "! rm -f song.mp3  # remove the song.mp3 if it exists\n",
        "#files.upload()\n",
        "! echo \"Moving song.mp3....\"\n",
        "#! mv song.mp3 spleeter/audio_example.mp3\n",
        "  \n",
        "# assign files \n",
        "input_file =\"/content/ss.mp3\" # \"/content/*.mp3\"\n",
        "output_file = \"/content/ss.wav\"\n",
        "path=output_file\n",
        "\n",
        "# convert mp3 file to wav file \n",
        "#sound = AudioSegment.from_mp3(input_file) \n",
        "#sound.export(output_file, format=\"wav\")"
      ],
      "metadata": {
        "id": "Mx3R3injtkEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.378188Z",
          "start_time": "2020-01-24T06:23:45.002029Z"
        },
        "id": "BRLi4300roGJ"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/timsainb/noisereduce/master/assets/fish.wav\"\n",
        "url = \"https://github.com/soheilpaper/So-AI-Love-/raw/master/assets/ss.wav\"\n",
        "\n",
        "url = \" https://www2.cs.uic.edu/~i101/SoundFiles/preamble10.wav\" #\"https://file-examples.com/wp-content/uploads/2017/11/file_example_WAV_1MG.wav\"\n",
        "#response = urllib.request.urlopen(url)\n",
        "#data, rate = sf.read(io.BytesIO(response.read()))\n",
        "#data = data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, rate =sf.read('/content/silero-models/recorded.wav')\n",
        "data = data"
      ],
      "metadata": {
        "id": "Eoy0kBqmOsvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.451295Z",
          "start_time": "2020-01-24T06:23:45.380357Z"
        },
        "id": "vrpQrFmAroGM"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=data, rate=rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.730517Z",
          "start_time": "2020-01-24T06:23:45.454586Z"
        },
        "id": "v5mUk9PqroGT"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2QzUvgProGX"
      },
      "source": [
        "### add noise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Either record audio from microphone or upload audio from file (.mp3 or .wav) { run: \"auto\" }\n",
        "\n",
        "record_or_upload = \"Record\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "record_seconds =  8 #@param {type:\"number\", min:1, max:10, step:1}\n",
        "sample_rate = 16000\n",
        "global rec_v\n",
        "rec_v=0\n",
        "\n",
        "def _apply_vad(audio, boot_time=0, trigger_level=9, **kwargs):\n",
        "  print('\\nVAD applied\\n')\n",
        "  vad_kwargs = dict(locals().copy(), **kwargs)\n",
        "  vad_kwargs['sample_rate'] = sample_rate\n",
        "  del vad_kwargs['kwargs'], vad_kwargs['audio']\n",
        "  audio = vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "  return vad(torch.flip(audio, ([0])), **vad_kwargs)\n",
        "\n",
        "def _recognize(audio):\n",
        "  display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "  if use_VAD == \"Yes\":\n",
        "    audio = _apply_vad(audio)\n",
        "  wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  transcription = wav_to_text()\n",
        "  print('\\n\\nTRANSCRIPTION:\\n')\n",
        "  print(transcription)\n",
        "\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds)\n",
        "  wavfile.write('ٔNoise_recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int16))\n",
        "  _recognize(audio)\n",
        "  \n",
        "  rec_v=1\n",
        "  #while True:\n",
        "     \n",
        "  return rec_v\n",
        "\n",
        "  \n",
        "\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = upload_audio()\n",
        "  _recognize(audio)\n",
        "  return audio\n",
        "import keyboard\n",
        "\n",
        "if True:\n",
        "   if record_or_upload == \"Record\":\n",
        "      button = widgets.Button(description=\"Record Speech\")\n",
        "      display(button)\n",
        "      if True :\n",
        "          button.on_click(_record_audio)\n",
        "          #if rec_v == \"1\":\n",
        "\n",
        "             #break\n",
        "      #input('press key to continue')\n",
        "      \n",
        "      #keyboard.get_event()\n",
        "      \n",
        "      #while rec_v!=1:\n",
        "      #    print (\"wating\")\n",
        "\n",
        "   else:\n",
        "      audio = _upload_audio(\"\")\n",
        "      rec_v=1"
      ],
      "metadata": {
        "id": "E9v9yj0kDuj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_data, noise_rate = sf.read('/content/silero-models/ٔNoise_recorded.wav')"
      ],
      "metadata": {
        "id": "iQPmZtcIFXaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:48.387747Z",
          "start_time": "2020-01-24T06:23:48.106920Z"
        },
        "id": "Wb7I4aVsroG3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,4))\n",
        "ax.plot(noise_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:48.455695Z",
          "start_time": "2020-01-24T06:23:48.389339Z"
        },
        "id": "hYy_k_VmroG5"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=noise_data, rate=noise_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.789926Z",
          "start_time": "2020-01-24T06:23:45.731671Z"
        },
        "id": "B1MdUHn1roGZ"
      },
      "outputs": [],
      "source": [
        "noise_len = 2 # seconds\n",
        "noise = band_limited_noise(min_freq=2000, max_freq = 12000, samples=len(data), samplerate=rate)*10\n",
        "noise_clip = noise[:rate*noise_len]\n",
        "audio_clip_band_limited = data+noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:46.068009Z",
          "start_time": "2020-01-24T06:23:45.791074Z"
        },
        "id": "rtQiBKdyroGc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_band_limited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:46.136220Z",
          "start_time": "2020-01-24T06:23:46.069398Z"
        },
        "id": "PSxtuTmlroGf"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=audio_clip_band_limited, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fDDmlOIroGi"
      },
      "source": [
        "### Stationary remove noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.537123Z",
          "start_time": "2020-01-24T06:23:46.137584Z"
        },
        "scrolled": false,
        "id": "EGbNWQ_7roGk"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_band_limited, sr=rate, n_std_thresh_stationary=1.5,stationary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.794652Z",
          "start_time": "2020-01-24T06:23:47.540334Z"
        },
        "id": "Q0hSDFQ9roGm"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(reduced_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.863889Z",
          "start_time": "2020-01-24T06:23:47.796686Z"
        },
        "id": "wtYZQ0tgroGp"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM0JYSW8roGs"
      },
      "source": [
        "### Non-stationary noise reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74c9F3YYroGu"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_band_limited, sr=rate, thresh_n_mult_nonstationary=2,stationary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp_HrCoEroGw"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(reduced_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-03-06T20:38:03.940928Z",
          "start_time": "2019-03-06T20:38:03.781906Z"
        },
        "id": "lrFnvpXproGz"
      },
      "source": [
        "## A more difficult example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:48.105354Z",
          "start_time": "2020-01-24T06:23:47.865305Z"
        },
        "id": "Hd2Hp4hlroG0"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/timsainb/noisereduce/master/assets/cafe_short.wav\"\n",
        "#response = urllib.request.urlopen(url)\n",
        "#noise_data, noise_rate = sf.read(io.BytesIO(response.read()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEsbLiHoroG9"
      },
      "source": [
        "### add noise to data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:48.516177Z",
          "start_time": "2020-01-24T06:23:48.502314Z"
        },
        "id": "6QRjObdiroG-"
      },
      "outputs": [],
      "source": [
        "snr = 2 # signal to noise ratio\n",
        "noise_clip = noise_data/snr\n",
        "audio_clip_cafe = data + noise_clip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xZ0wegEroHA"
      },
      "source": [
        "### plot noisy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:48.934704Z",
          "start_time": "2020-01-24T06:23:48.517449Z"
        },
        "id": "vYgHoBs_roHC"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,4))\n",
        "ax.plot(audio_clip_cafe)\n",
        "IPython.display.Audio(data=audio_clip_cafe, rate=noise_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUMQmfvroHE"
      },
      "source": [
        "### Stationary remove noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.537123Z",
          "start_time": "2020-01-24T06:23:46.137584Z"
        },
        "scrolled": false,
        "id": "vR5L1wKlroHF"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_cafe, sr=rate, y_noise = noise_clip, n_std_thresh_stationary=1.5,stationary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.794652Z",
          "start_time": "2020-01-24T06:23:47.540334Z"
        },
        "id": "zb1q9r2iroHH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_cafe)\n",
        "ax.plot(reduced_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.863889Z",
          "start_time": "2020-01-24T06:23:47.796686Z"
        },
        "id": "nGR-MbcdroHJ"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv69I-tCroHL"
      },
      "source": [
        "### Non-stationary noise reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6oEY3FIroHM"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_cafe, sr=rate, thresh_n_mult_nonstationary=2,stationary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:55.649193Z",
          "start_time": "2020-01-24T06:23:55.225762Z"
        },
        "id": "wNmuqay1roHO"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_cafe)\n",
        "ax.plot(reduced_noise, alpha = 1)\n",
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yi1WdChXroHQ"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8zTiP76roHT"
      },
      "source": [
        "### ensure that noise reduction does not cause distortion when prop_decrease == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:24:53.912192Z",
          "start_time": "2020-01-24T06:24:53.332737Z"
        },
        "id": "mM0qVwreroHV"
      },
      "outputs": [],
      "source": [
        "noise_reduced = nr.reduce_noise(y=data, sr=rate, prop_decrease=0, stationary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:24:54.091032Z",
          "start_time": "2020-01-24T06:24:53.913458Z"
        },
        "id": "IyiH80PvroHX"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(20,6))\n",
        "axs[0].plot(data[3000:5000])\n",
        "axs[0].plot(noise_reduced[3000:5000])\n",
        "axs[1].plot(data)\n",
        "axs[1].plot(noise_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:24:53.912192Z",
          "start_time": "2020-01-24T06:24:53.332737Z"
        },
        "id": "ILtdvUVhroHa"
      },
      "outputs": [],
      "source": [
        "noise_reduced = nr.reduce_noise(y=data, sr=rate, prop_decrease=0, stationary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:24:54.091032Z",
          "start_time": "2020-01-24T06:24:53.913458Z"
        },
        "id": "VKB704N5roHc"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(20,6))\n",
        "axs[0].plot(data[3000:5000])\n",
        "axs[0].plot(noise_reduced[3000:5000])\n",
        "axs[1].plot(data)\n",
        "axs[1].plot(noise_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB_lEXiRroHf"
      },
      "source": [
        "### Reduce noise over batches in parallel on long signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSjTMGznroHg"
      },
      "outputs": [],
      "source": [
        "long_data = np.tile(data, 10)\n",
        "len(long_data)/rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NkPCvKsroHh"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,4))\n",
        "ax.plot(long_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:45.789926Z",
          "start_time": "2020-01-24T06:23:45.731671Z"
        },
        "id": "8tdKYn_kroHj"
      },
      "outputs": [],
      "source": [
        "noise = band_limited_noise(min_freq=2000, max_freq = 12000, samples=len(long_data), samplerate=rate)*10\n",
        "audio_clip_band_limited = long_data+noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:46.068009Z",
          "start_time": "2020-01-24T06:23:45.791074Z"
        },
        "id": "-Zs3zVPJroHl"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_band_limited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alQ81nuSroHo"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(\n",
        "    y=audio_clip_band_limited,\n",
        "    sr=rate,\n",
        "    thresh_n_mult_nonstationary=2,\n",
        "    stationary=False,\n",
        "    n_jobs=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaYOG12sroHq"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_band_limited)\n",
        "ax.plot(reduced_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUlX1ncUroHs"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(\n",
        "    y=audio_clip_band_limited,\n",
        "    sr=rate,\n",
        "    thresh_n_mult_nonstationary=2,\n",
        "    stationary=True,\n",
        "    n_jobs=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUkZQdP9roHv"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_band_limited)\n",
        "ax.plot(reduced_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5MwtWi9roHx"
      },
      "source": [
        "### Reduce noise on only a subset of a long clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPaHVE0eroHz"
      },
      "outputs": [],
      "source": [
        "from noisereduce.noisereduce import SpectralGateStationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_IbYGlgroH0"
      },
      "outputs": [],
      "source": [
        "sg = SpectralGateStationary(\n",
        "    y = data,\n",
        "    sr = rate,\n",
        "    y_noise=None,\n",
        "    prop_decrease=1.0,\n",
        "    time_constant_s=2.0,\n",
        "    freq_mask_smooth_hz=500,\n",
        "    time_mask_smooth_ms=50,\n",
        "    n_std_thresh_stationary=1.5,\n",
        "    tmp_folder=None,\n",
        "    chunk_size=600000,\n",
        "    padding=30000,\n",
        "    n_fft=1024,\n",
        "    win_length=None,\n",
        "    hop_length=None,\n",
        "    clip_noise_stationary=True,\n",
        "    use_tqdm=False,\n",
        "    n_jobs=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WgJGLUJroH3"
      },
      "outputs": [],
      "source": [
        "subset_noise_reduce = sg.get_traces(start_frame = 10000, end_frame = 20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_BG2L51roH5"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(subset_noise_reduce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ8m5QsDroH7"
      },
      "source": [
        "## Multichannel noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3w9TXdHroH9"
      },
      "outputs": [],
      "source": [
        "audio_clip_cafe_2_channel = np.vstack([audio_clip_cafe, audio_clip_cafe])\n",
        "audio_clip_cafe_2_channel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.537123Z",
          "start_time": "2020-01-24T06:23:46.137584Z"
        },
        "scrolled": false,
        "id": "Mtc8nSdnroH_"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_cafe_2_channel, sr=rate, n_std_thresh_stationary=1.5,stationary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO0onoouroIA"
      },
      "outputs": [],
      "source": [
        "reduced_noise.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.794652Z",
          "start_time": "2020-01-24T06:23:47.540334Z"
        },
        "id": "mt4IY4xtroID"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows= 2, figsize=(20,5))\n",
        "axs[0].plot(audio_clip_cafe_2_channel[0])\n",
        "axs[1].plot(audio_clip_cafe_2_channel[1])\n",
        "\n",
        "axs[0].plot(reduced_noise[0])\n",
        "axs[1].plot(reduced_noise[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:47.863889Z",
          "start_time": "2020-01-24T06:23:47.796686Z"
        },
        "id": "8cWRD31hroIE"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkdFeB6iroIG"
      },
      "outputs": [],
      "source": [
        "reduced_noise = nr.reduce_noise(y = audio_clip_cafe, sr=rate, thresh_n_mult_nonstationary=2,stationary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JESA8QQ3roII"
      },
      "outputs": [],
      "source": [
        "reduced_noise.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-24T06:23:55.649193Z",
          "start_time": "2020-01-24T06:23:55.225762Z"
        },
        "id": "-p9h1zz3roIK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,3))\n",
        "ax.plot(audio_clip_cafe)\n",
        "ax.plot(reduced_noise, alpha = 1)\n",
        "IPython.display.Audio(data=reduced_noise, rate=rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pC6zX8rroIM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "neuroethology",
      "language": "python",
      "name": "neuroethology"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}